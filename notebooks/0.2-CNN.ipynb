{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a3ece0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "86dad5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D, Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b9b3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '../data/raw/train/'\n",
    "test_data = '../data/raw/test/'\n",
    "val_data = '../data/raw/val/'\n",
    "\n",
    "process_train = '../data/processed/train/'\n",
    "process_test = '../data/processed/test/'\n",
    "process_val = '../data/processed/val/'\n",
    "\n",
    "category_names = ['messy/', 'clean/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "93137c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GrayScale with new size 50x50\n",
    "\n",
    "clean_train = []\n",
    "messy_train = []\n",
    "y_train = []\n",
    "\n",
    "for category in category_names:\n",
    "    \n",
    "    path_processed = process_train+category\n",
    "    \n",
    "    for image in os.listdir(path_processed):\n",
    "        \n",
    "        image_treatment = Image.open(path_processed+image).resize((50,50))\n",
    "        \n",
    "        if category == 'messy/' :\n",
    "            messy = np.asarray(image_treatment) /255 # bit format\n",
    "            messy_train.append(messy)\n",
    "            y_train.append([1])\n",
    "        else:\n",
    "            clean = np.asarray(image_treatment)/255 # bit format\n",
    "            clean_train.append(clean)\n",
    "            y_train.append([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a047784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GrayScale with new size 50x50\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for category in category_names:\n",
    "    \n",
    "    path_processed = process_val+category\n",
    "    \n",
    "    for image in os.listdir(path_processed):\n",
    "        \n",
    "        image_treatment = Image.open(path_processed+image).resize((50,50))\n",
    "        \n",
    "        if category == 'messy/' :\n",
    "            messy = np.asarray(image_treatment) /255 # bit format\n",
    "            x_val.append(messy)\n",
    "            y_val.append(1)\n",
    "        else:\n",
    "            clean = np.asarray(image_treatment)/255 # bit format\n",
    "            x_val.append(clean)\n",
    "            y_val.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2bb960b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messy: (96, 50, 50, 2) clean: (96, 50, 50, 2)\n",
      "train x =  (192, 50, 50, 2)\n",
      "train y =  (192, 1)\n",
      "val x =  (20, 50, 50, 2)\n",
      "val y =  (20,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate((messy_train,clean_train),axis=0)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(\"messy:\", np.shape(messy_train) , \"clean:\", np.shape(clean_train))\n",
    "\n",
    "print('train x = ', x_train.shape)\n",
    "print('train y = ', y_train.shape)\n",
    "print('val x = ', x_val.shape)\n",
    "print('val y = ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f950143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', input_shape=(x_train.shape[1:]) ) )\n",
    "    model.add(AveragePooling2D(2,2))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(AveragePooling2D(2,2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense( 1, activation=\"sigmoid\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "be30c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f182a0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 48, 48, 64)        1216      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_64 (Averag (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 22, 22, 32)        18464     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_65 (Averag (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 3873      \n",
      "=================================================================\n",
      "Total params: 23,553\n",
      "Trainable params: 23,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "49d0bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer='adam', loss='binary_crossentropy', metrics = ['acc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2a10c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.0181 - val_acc: 0.6500\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.0326 - val_acc: 0.6500\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.0405 - val_acc: 0.6500\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.0814 - val_acc: 0.6500\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.0739 - val_acc: 0.6500\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.0897 - val_acc: 0.6500\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1094 - val_acc: 0.6500\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.1090 - val_acc: 0.6500\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.1326 - val_acc: 0.6500\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.1570 - val_acc: 0.6500\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.1766 - val_acc: 0.6500\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.1951 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.1857 - val_acc: 0.6500\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.2301 - val_acc: 0.6500\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.2207 - val_acc: 0.6500\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.2353 - val_acc: 0.6500\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.2542 - val_acc: 0.6500\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2587 - val_acc: 0.6500\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.2808 - val_acc: 0.6500\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.2877 - val_acc: 0.6500\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.2923 - val_acc: 0.6500\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.2994 - val_acc: 0.6500\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.3271 - val_acc: 0.6500\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.3388 - val_acc: 0.6500\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.3569 - val_acc: 0.6500\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.3670 - val_acc: 0.6500\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.3619 - val_acc: 0.6500\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.3790 - val_acc: 0.6500\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.3875 - val_acc: 0.6500\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.4017 - val_acc: 0.6500\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.4144 - val_acc: 0.6500\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.4212 - val_acc: 0.6500\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.4398 - val_acc: 0.6500\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.4413 - val_acc: 0.6500\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.4465 - val_acc: 0.6500\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.4581 - val_acc: 0.6500\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.4798 - val_acc: 0.6500\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.4916 - val_acc: 0.6500\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.4908 - val_acc: 0.6500\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.5071 - val_acc: 0.6500\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.5092 - val_acc: 0.6500\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.5307 - val_acc: 0.6500\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.5278 - val_acc: 0.6500\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.5353 - val_acc: 0.6500\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.5465 - val_acc: 0.6500\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5564 - val_acc: 0.6500\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5610 - val_acc: 0.6500\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5776 - val_acc: 0.6500\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.5782 - val_acc: 0.6500\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.5883 - val_acc: 0.6500\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.5913 - val_acc: 0.6500\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6003 - val_acc: 0.6500\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6123 - val_acc: 0.6500\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6140 - val_acc: 0.6500\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6284 - val_acc: 0.6500\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.6361 - val_acc: 0.6500\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.6516 - val_acc: 0.6500\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6471 - val_acc: 0.6500\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.6703 - val_acc: 0.6500\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6663 - val_acc: 0.6500\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 1s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6800 - val_acc: 0.6500\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6967 - val_acc: 0.6500\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.6971 - val_acc: 0.6500\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7010 - val_acc: 0.6500\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7138 - val_acc: 0.6500\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7244 - val_acc: 0.6500\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7157 - val_acc: 0.6500\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.7386 - val_acc: 0.6500\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.7398 - val_acc: 0.6500\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 9.9596e-04 - acc: 1.0000 - val_loss: 2.7522 - val_acc: 0.6500\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 9.8625e-04 - acc: 1.0000 - val_loss: 2.7612 - val_acc: 0.6500\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.7565 - val_acc: 0.6500\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 9.7372e-04 - acc: 1.0000 - val_loss: 2.7752 - val_acc: 0.6500\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 9.6836e-04 - acc: 1.0000 - val_loss: 2.7659 - val_acc: 0.6500\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 9.1733e-04 - acc: 1.0000 - val_loss: 2.7801 - val_acc: 0.6500\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 9.1777e-04 - acc: 1.0000 - val_loss: 2.7773 - val_acc: 0.6500\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 9.1272e-04 - acc: 1.0000 - val_loss: 2.7862 - val_acc: 0.6500\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 8.7138e-04 - acc: 1.0000 - val_loss: 2.8022 - val_acc: 0.6500\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 8.6104e-04 - acc: 1.0000 - val_loss: 2.8061 - val_acc: 0.6500\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 8.5511e-04 - acc: 1.0000 - val_loss: 2.8201 - val_acc: 0.6500\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 8.2602e-04 - acc: 1.0000 - val_loss: 2.8256 - val_acc: 0.6500\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 8.3492e-04 - acc: 1.0000 - val_loss: 2.8316 - val_acc: 0.6500\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 8.0013e-04 - acc: 1.0000 - val_loss: 2.8471 - val_acc: 0.6500\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 7.9299e-04 - acc: 1.0000 - val_loss: 2.8418 - val_acc: 0.6500\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 7.7513e-04 - acc: 1.0000 - val_loss: 2.8510 - val_acc: 0.6500\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 7.6449e-04 - acc: 1.0000 - val_loss: 2.8585 - val_acc: 0.6500\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 7.5175e-04 - acc: 1.0000 - val_loss: 2.8598 - val_acc: 0.6500\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 7.4338e-04 - acc: 1.0000 - val_loss: 2.8653 - val_acc: 0.6500\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 7.2688e-04 - acc: 1.0000 - val_loss: 2.8749 - val_acc: 0.6500\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 7.2009e-04 - acc: 1.0000 - val_loss: 2.8803 - val_acc: 0.6500\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 7.1943e-04 - acc: 1.0000 - val_loss: 2.8840 - val_acc: 0.6500\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 7.1895e-04 - acc: 1.0000 - val_loss: 2.9050 - val_acc: 0.6500\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 6.8935e-04 - acc: 1.0000 - val_loss: 2.8896 - val_acc: 0.6500\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 6.7960e-04 - acc: 1.0000 - val_loss: 2.9060 - val_acc: 0.6500\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 6.6426e-04 - acc: 1.0000 - val_loss: 2.9144 - val_acc: 0.6500\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 6.5482e-04 - acc: 1.0000 - val_loss: 2.9235 - val_acc: 0.6500\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 6.4482e-04 - acc: 1.0000 - val_loss: 2.9230 - val_acc: 0.6500\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 6.5176e-04 - acc: 1.0000 - val_loss: 2.9318 - val_acc: 0.6500\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 6.4032e-04 - acc: 1.0000 - val_loss: 2.9412 - val_acc: 0.6500\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 6.2754e-04 - acc: 1.0000 - val_loss: 2.9457 - val_acc: 0.6500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, steps_per_epoch= 10, validation_data = (x_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "54138517",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-0868c466b308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e48ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
